entropy is used to measure how informative is a node.
Entropy of P:
$$Info(P)=-(p_1logp_1+p_2logp_2+p_3logp_3+...+p_nlogp_n)$$
the smaller the entropy, the more informative we have.


